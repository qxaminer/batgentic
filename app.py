"""
BatGentic Streamlit Application

Interactive web interface for bioacoustic analysis tool for bat call validation and sonification.
"""

import streamlit as st
import pandas as pd
import numpy as np
from pathlib import Path
import tempfile
import zipfile
import io
import logging
import sys
from typing import Dict, List, Optional, Tuple

# Try to import plotly, fall back to matplotlib if not available
try:
    import plotly.express as px
    import plotly.graph_objects as go
    PLOTLY_AVAILABLE = True
except ImportError:
    px = None
    go = None
    PLOTLY_AVAILABLE = False
    # Import matplotlib as fallback
    import matplotlib.pyplot as plt
    import matplotlib
    matplotlib.use('Agg')  # Use non-interactive backend

# Add src to path so we can import from our package structure
sys.path.append(str(Path(__file__).parent / "src"))

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Import our custom modules - with graceful handling for cloud deployment
try:
    from batgentic.processing.sonobat_parser import SonoBatParser
    from batgentic.utils.utils import create_output_directory, validate_audio_file
    AUDIO_PROCESSING_AVAILABLE = True
    try:
        from batgentic.processing.audio_processor import AudioProcessor
    except ImportError:
        # Audio processing not available in cloud demo - that's OK!
        AudioProcessor = None
        AUDIO_PROCESSING_AVAILABLE = False
except ImportError as e:
    st.error(f"BatGentic modules not found: {e}")
    st.error("Please check the package installation and file paths.")
    st.stop()

# Page configuration
st.set_page_config(
    page_title="BatGentic - Bat Call Analysis",
    page_icon="ðŸ¦‡",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for better styling
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #2E86AB;
        text-align: center;
        margin-bottom: 2rem;
    }
    .feature-box {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    .metric-container {
        background-color: #ffffff;
        padding: 1rem;
        border-radius: 0.5rem;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .stAlert > div {
        padding-top: 1rem;
    }
</style>
""", unsafe_allow_html=True)

# Initialize session state
if 'parser' not in st.session_state:
    st.session_state.parser = SonoBatParser()
if 'processor' not in st.session_state:
    st.session_state.processor = AudioProcessor() if AUDIO_PROCESSING_AVAILABLE else None
if 'validation_data' not in st.session_state:
    st.session_state.validation_data = None
if 'processed_files' not in st.session_state:
    st.session_state.processed_files = []


def main():
    """Main application function."""
    
    # Header
    st.markdown('<div class="main-header">ðŸ¦‡ BatGentic</div>', unsafe_allow_html=True)
    demo_subtitle = "Cloud Demo - Data Analysis & Visualization" if not AUDIO_PROCESSING_AVAILABLE else "Interactive Bioacoustic Analysis Tool for Bat Call Validation and Sonification"
    st.markdown(f"""
    <div style="text-align: center; margin-bottom: 2rem; color: #666;">
        {demo_subtitle}
    </div>
    """, unsafe_allow_html=True)
    
    if not AUDIO_PROCESSING_AVAILABLE:
        st.info("ðŸŽ¯ **Demo Mode:** Showcasing data parsing, species analysis, and visualization capabilities. Audio processing available in local installation.")
    
    # Sidebar
    with st.sidebar:
        st.header("ðŸ”§ Configuration")
        
        # Processing parameters
        st.subheader("Audio Processing")
        pitch_shift = st.slider(
            "Pitch Shift (cents)",
            min_value=-4800,
            max_value=-600,
            value=-2400,
            step=100,
            help="Negative values shift pitch down. -2400 cents = 2 octaves down"
        )
        
        sample_rate = st.selectbox(
            "Target Sample Rate (Hz)",
            options=[22050, 44100, 48000],
            index=0,
            help="Higher sample rates preserve more detail but increase file size"
        )
        
        st.subheader("Validation Filters")
        min_confidence = st.slider(
            "Minimum Confidence Score",
            min_value=0.0,
            max_value=1.0,
            value=0.0,
            step=0.1,
            help="Filter out calls below this confidence threshold"
        )
        
        st.subheader("Export Options")
        include_metadata = st.checkbox("Include metadata files", value=True)
        create_species_folders = st.checkbox("Organize by species", value=True)
    
    # Main content tabs
    tab1, tab2, tab3, tab4 = st.tabs(["ðŸ“ Upload & Parse", "ðŸ”Š Audio Processing", "ðŸ“Š Analysis", "ðŸ“¦ Export"])
    
    with tab1:
        upload_and_parse_tab(min_confidence)
    
    with tab2:
        audio_processing_tab(pitch_shift, sample_rate)
    
    with tab3:
        analysis_tab()
    
    with tab4:
        export_tab(include_metadata, create_species_folders)


def upload_and_parse_tab(min_confidence: float):
    """Handle file upload and parsing."""
    
    st.header("ðŸ“ Upload SonoBat Validation File")
    
    uploaded_file = st.file_uploader(
        "Choose a SonoBat validation file (.txt)",
        type=['txt'],
        help="Upload a tab-separated SonoBat validation file"
    )
    
    if uploaded_file is not None:
        try:
            # Create temporary file
            with tempfile.NamedTemporaryFile(delete=False, suffix='.txt') as tmp_file:
                tmp_file.write(uploaded_file.getvalue())
                tmp_file_path = tmp_file.name
            
            with st.spinner("Parsing validation file..."):
                # Load and parse the file
                st.session_state.parser.load_validation_file(tmp_file_path)
                
                # Extract validated calls
                validated_calls = st.session_state.parser.extract_validated_calls(
                    min_confidence=min_confidence
                )
                st.session_state.validation_data = validated_calls
            
            # Display results
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric(
                    "Total Records",
                    len(st.session_state.parser.data),
                    help="Total number of records in the file"
                )
            
            with col2:
                st.metric(
                    "Validated Calls",
                    len(validated_calls),
                    help="Calls meeting validation criteria"
                )
            
            with col3:
                validation_rate = (len(validated_calls) / len(st.session_state.parser.data)) * 100
                st.metric(
                    "Validation Rate",
                    f"{validation_rate:.1f}%",
                    help="Percentage of calls that passed validation"
                )
            
            # Display data preview
            st.subheader("ðŸ“‹ Validation Data Preview")
            
            if len(validated_calls) > 0:
                # Show sample of data
                st.dataframe(
                    validated_calls.head(20),
                    use_container_width=True
                )
                
                # Species summary
                species_summary = st.session_state.parser.get_species_summary()
                if species_summary:
                    st.subheader("ðŸ¦‡ Species Distribution")
                    
                    species_df = pd.DataFrame(
                        list(species_summary.items()),
                        columns=['Species', 'Count']
                    )
                    
                    if PLOTLY_AVAILABLE:
                        fig = px.bar(
                            species_df,
                            x='Species',
                            y='Count',
                            title="Number of Validated Calls by Species"
                        )
                        fig.update_layout(xaxis_tickangle=-45)
                        st.plotly_chart(fig, use_container_width=True)
                    else:
                        # Fallback to simple bar chart display
                        st.bar_chart(species_df.set_index('Species'))
                
                # Confidence score distribution
                try:
                    confidence_col = st.session_state.parser._find_confidence_column()
                    
                    if PLOTLY_AVAILABLE:
                        fig = px.histogram(
                            validated_calls,
                            x=confidence_col,
                            title="Confidence Score Distribution",
                            nbins=20
                        )
                        st.plotly_chart(fig, use_container_width=True)
                    else:
                        # Simple histogram with streamlit
                        st.subheader("ðŸ“ˆ Confidence Score Distribution")
                        st.histogram_chart(validated_calls[confidence_col])
                    
                except Exception as e:
                    st.warning(f"Could not display confidence distribution: {e}")
            
            else:
                st.warning("No validated calls found with the current filter criteria.")
            
            # Clean up temporary file
            Path(tmp_file_path).unlink(missing_ok=True)
            
        except Exception as e:
            st.error(f"Error parsing validation file: {str(e)}")
            logger.error(f"Parsing error: {e}")


def audio_processing_tab(pitch_shift: float, sample_rate: int):
    """Handle audio processing operations."""
    
    st.header("ðŸ”Š Audio Processing")
    
    if not AUDIO_PROCESSING_AVAILABLE:
        st.info("ðŸŽµ **Audio Processing Demo Mode**")
        st.markdown("""
        Audio processing features are available in the local installation but not in this cloud demo.
        
        **This demo focuses on:**
        - âœ… SonoBat validation file parsing
        - âœ… Species analysis and visualization  
        - âœ… Data filtering and export capabilities
        - âœ… Professional data processing workflows
        
        **For full audio processing capabilities:**
        - Clone the repository: `git clone https://github.com/qxaminer/batgentic.git`
        - Install with audio dependencies: `pip install librosa soundfile`
        - Run locally: `streamlit run app.py`
        """)
        return
    
    if st.session_state.validation_data is None:
        st.info("ðŸ‘† Please upload and parse a validation file first.")
        return
    
    # Audio directory selection
    st.subheader("ðŸ“‚ Audio Files Location")
    
    audio_directory = st.text_input(
        "Audio files directory path",
        placeholder="/path/to/audio/files",
        help="Directory containing the original .wav files"
    )
    
    # File upload option for audio files
    st.markdown("**Or upload audio files directly:**")
    uploaded_audio_files = st.file_uploader(
        "Upload audio files",
        type=['wav', 'mp3', 'flac'],
        accept_multiple_files=True,
        help="Upload the audio files corresponding to validated calls"
    )
    
    if audio_directory or uploaded_audio_files:
        
        # Process uploaded files or find files in directory
        if uploaded_audio_files:
            audio_file_paths = []
            temp_dir = Path(tempfile.mkdtemp())
            
            for uploaded_file in uploaded_audio_files:
                temp_path = temp_dir / uploaded_file.name
                with open(temp_path, 'wb') as f:
                    f.write(uploaded_file.getbuffer())
                
                # Try to match with validation data
                filename_base = Path(uploaded_file.name).stem
                matching_rows = st.session_state.validation_data[
                    st.session_state.validation_data.apply(
                        lambda row: filename_base in str(row.iloc[0]) if len(row) > 0 else False,
                        axis=1
                    )
                ]
                
                if not matching_rows.empty:
                    try:
                        species = matching_rows.iloc[0][st.session_state.parser._find_species_column()]
                    except:
                        species = "Unknown"
                    audio_file_paths.append((species, temp_path))
        
        else:
            # Find audio files in directory
            try:
                audio_file_paths = st.session_state.parser.get_audio_file_paths(Path(audio_directory))
            except Exception as e:
                st.error(f"Error finding audio files: {str(e)}")
                return
        
        if not audio_file_paths:
            st.warning("No matching audio files found.")
            return
        
        st.success(f"Found {len(audio_file_paths)} audio files to process.")
        
        # Display file list
        with st.expander(f"View {len(audio_file_paths)} files to process"):
            files_df = pd.DataFrame(
                [(species, Path(path).name) for species, path in audio_file_paths],
                columns=['Species', 'Filename']
            )
            st.dataframe(files_df, use_container_width=True)
        
        # Processing options
        col1, col2 = st.columns(2)
        
        with col1:
            process_all = st.button(
                "ðŸŽµ Process All Files",
                type="primary",
                help="Process all files with current settings"
            )
        
        with col2:
            preview_mode = st.checkbox(
                "Preview mode (first 10 files only)",
                value=False,
                help="Process only first 10 files for testing"
            )
        
        # Process files
        if process_all:
            
            files_to_process = audio_file_paths[:10] if preview_mode else audio_file_paths
            
            # Create output directory
            output_dir = create_output_directory(Path.cwd(), "processed_audio")
            
            # Prepare file paths for processing
            processing_list = []
            for species, input_path in files_to_process:
                output_filename = f"{Path(input_path).stem}_processed.wav"
                output_path = output_dir / "processed" / output_filename
                processing_list.append((species, input_path, output_path))
            
            # Process with progress bar
            with st.spinner("Processing audio files..."):
                
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                results = []
                
                for i, (species, input_path, output_path) in enumerate(processing_list):
                    try:
                        # Update progress
                        progress = (i + 1) / len(processing_list)
                        progress_bar.progress(progress)
                        status_text.text(f"Processing: {Path(input_path).name} ({i+1}/{len(processing_list)})")
                        
                        # Process single file
                        if st.session_state.processor:
                            st.session_state.processor.sample_rate = sample_rate
                            metadata = st.session_state.processor.process_single_file(
                                input_path, output_path, pitch_shift
                            )
                            metadata['species'] = species
                            metadata['status'] = 'success'
                            results.append(metadata)
                        else:
                            # Audio processing not available in demo mode
                            metadata = {
                                'input_path': str(input_path),
                                'species': species,
                                'status': 'demo_mode',
                                'message': 'Audio processing available in local installation'
                            }
                            results.append(metadata)
                        
                    except Exception as e:
                        error_metadata = {
                            'input_path': str(input_path),
                            'species': species,
                            'status': 'failed',
                            'error': str(e)
                        }
                        results.append(error_metadata)
                        logger.error(f"Processing failed for {input_path}: {e}")
                
                # Clear progress indicators
                progress_bar.empty()
                status_text.empty()
                
                st.session_state.processed_files = results
            
            # Display results
            successful = len([r for r in results if r['status'] == 'success'])
            failed = len([r for r in results if r['status'] == 'failed'])
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("âœ… Successful", successful)
            with col2:
                st.metric("âŒ Failed", failed)
            with col3:
                success_rate = (successful / len(results)) * 100 if results else 0
                st.metric("Success Rate", f"{success_rate:.1f}%")
            
            if successful > 0:
                st.success(f"Successfully processed {successful} files!")
                
                # Show processing summary
                with st.expander("View processing details"):
                    results_df = pd.DataFrame(results)
                    st.dataframe(results_df, use_container_width=True)
            
            if failed > 0:
                st.error(f"{failed} files failed to process.")
                failed_files = [r for r in results if r['status'] == 'failed']
                with st.expander("View failed files"):
                    failed_df = pd.DataFrame(failed_files)
                    st.dataframe(failed_df[['input_path', 'species', 'error']], use_container_width=True)


def analysis_tab():
    """Display analysis and visualization."""
    
    st.header("ðŸ“Š Analysis Dashboard")
    
    if st.session_state.validation_data is None:
        st.info("ðŸ‘† Please upload and parse a validation file first.")
        return
    
    data = st.session_state.validation_data
    
    # Basic statistics
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Total Calls", len(data))
    
    with col2:
        try:
            species_count = data[st.session_state.parser._find_species_column()].nunique()
            st.metric("Species Count", species_count)
        except:
            st.metric("Species Count", "N/A")
    
    with col3:
        try:
            conf_col = st.session_state.parser._find_confidence_column()
            avg_confidence = data[conf_col].mean()
            st.metric("Avg Confidence", f"{avg_confidence:.3f}")
        except:
            st.metric("Avg Confidence", "N/A")
    
    with col4:
        if st.session_state.processed_files:
            processed_count = len([f for f in st.session_state.processed_files if f['status'] == 'success'])
            st.metric("Processed Files", processed_count)
        else:
            st.metric("Processed Files", 0)
    
    # Visualizations
    try:
        species_col = st.session_state.parser._find_species_column()
        conf_col = st.session_state.parser._find_confidence_column()
        
        # Species vs Confidence
        st.subheader("ðŸ“ˆ Species vs Confidence Analysis")
        
        if PLOTLY_AVAILABLE:
            fig = px.box(
                data,
                x=species_col,
                y=conf_col,
                title="Confidence Score Distribution by Species"
            )
            fig.update_layout(xaxis_tickangle=-45)
            st.plotly_chart(fig, use_container_width=True)
        else:
            # Simple visualization without plotly
            st.write("**Species vs Confidence Summary:**")
            species_conf_summary = data.groupby(species_col)[conf_col].agg(['mean', 'std', 'count']).round(3)
            st.dataframe(species_conf_summary)
        
        # Processing duration analysis (if available)
        if st.session_state.processed_files:
            processing_data = [f for f in st.session_state.processed_files if f['status'] == 'success']
            
            if processing_data and 'original_duration' in processing_data[0]:
                st.subheader("â±ï¸ Processing Time Analysis")
                
                durations_df = pd.DataFrame(processing_data)
                
                if PLOTLY_AVAILABLE:
                    fig = px.scatter(
                        durations_df,
                        x='original_duration',
                        y='processed_duration',
                        color='species',
                        title="Original vs Processed Duration",
                        labels={'original_duration': 'Original Duration (s)', 'processed_duration': 'Processed Duration (s)'}
                    )
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.write("**Processing Duration Summary:**")
                    st.dataframe(durations_df[['species', 'original_duration', 'processed_duration']])
        
    except Exception as e:
        st.warning(f"Could not generate all visualizations: {e}")
    
    # Data table with filtering
    st.subheader("ðŸ” Detailed Data View")
    
    # Filters
    col1, col2 = st.columns(2)
    
    with col1:
        try:
            species_col = st.session_state.parser._find_species_column()
            if species_col in data.columns:
                species_filter = st.multiselect(
                    "Filter by Species",
                    options=data[species_col].unique(),
                    default=[]
                )
            else:
                species_filter = []
        except:
            species_filter = []
    
    with col2:
        try:
            conf_col = st.session_state.parser._find_confidence_column()
            conf_range = st.slider(
                "Confidence Range",
                min_value=float(data[conf_col].min()),
                max_value=float(data[conf_col].max()),
                value=(float(data[conf_col].min()), float(data[conf_col].max()))
            )
        except:
            conf_range = None
    
    # Apply filters
    filtered_data = data.copy()
    
    if species_filter:
        try:
            species_col = st.session_state.parser._find_species_column()
            filtered_data = filtered_data[
                filtered_data[species_col].isin(species_filter)
            ]
        except:
            pass
    
    if conf_range:
        try:
            conf_col = st.session_state.parser._find_confidence_column()
            filtered_data = filtered_data[
                (filtered_data[conf_col] >= conf_range[0]) &
                (filtered_data[conf_col] <= conf_range[1])
            ]
        except:
            pass
    
    st.dataframe(filtered_data, use_container_width=True)


def export_tab(include_metadata: bool, create_species_folders: bool):
    """Handle data export functionality."""
    
    st.header("ðŸ“¦ Export Results")
    
    if st.session_state.validation_data is None:
        st.info("ðŸ‘† Please upload and parse a validation file first.")
        return
    
    # Export options
    st.subheader("Export Options")
    
    col1, col2 = st.columns(2)
    
    with col1:
        export_format = st.selectbox(
            "Export Format",
            options=['CSV', 'Excel', 'JSON'],
            help="Choose the format for exporting validation data"
        )
    
    with col2:
        include_processed = st.checkbox(
            "Include processed audio files",
            value=True,
            disabled=len(st.session_state.processed_files) == 0,
            help="Include processed audio files in the export package"
        )
    
    # Export buttons
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ðŸ“‹ Export Validation Data", type="primary"):
            export_validation_data(export_format)
    
    with col2:
        if st.button("ðŸ”Š Export Audio Files", disabled=len(st.session_state.processed_files) == 0):
            export_audio_files(create_species_folders)
    
    with col3:
        if st.button("ðŸ“¦ Export Complete Package"):
            export_complete_package(export_format, include_metadata, create_species_folders, include_processed)
    
    # Display export statistics
    if st.session_state.validation_data is not None:
        st.subheader("ðŸ“Š Export Summary")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("Validation Records", len(st.session_state.validation_data))
        
        with col2:
            processed_count = len([f for f in st.session_state.processed_files if f['status'] == 'success'])
            st.metric("Processed Audio Files", processed_count)
        
        with col3:
            try:
                species_count = st.session_state.validation_data[
                    st.session_state.parser._find_species_column()
                ].nunique()
                st.metric("Unique Species", species_count)
            except:
                st.metric("Unique Species", "N/A")


def export_validation_data(format_type: str):
    """Export validation data in specified format."""
    
    data = st.session_state.validation_data
    
    if format_type == 'CSV':
        csv_data = data.to_csv(index=False)
        st.download_button(
            label="ðŸ“¥ Download CSV",
            data=csv_data,
            file_name="batgentic_validation_data.csv",
            mime="text/csv"
        )
    
    elif format_type == 'Excel':
        buffer = io.BytesIO()
        with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
            data.to_excel(writer, sheet_name='Validation Data', index=False)
            
            # Add summary sheet
            try:
                summary = pd.DataFrame({
                    'Metric': ['Total Records', 'Unique Species', 'Average Confidence'],
                    'Value': [
                        len(data),
                        data[st.session_state.parser._find_species_column()].nunique(),
                        data[st.session_state.parser._find_confidence_column()].mean()
                    ]
                })
                summary.to_excel(writer, sheet_name='Summary', index=False)
            except:
                # If we can't create summary, skip it
                pass
        
        st.download_button(
            label="ðŸ“¥ Download Excel",
            data=buffer.getvalue(),
            file_name="batgentic_validation_data.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
    
    elif format_type == 'JSON':
        json_data = data.to_json(indent=2)
        st.download_button(
            label="ðŸ“¥ Download JSON",
            data=json_data,
            file_name="batgentic_validation_data.json",
            mime="application/json"
        )


def export_audio_files(create_species_folders: bool):
    """Export processed audio files as ZIP."""
    
    if not st.session_state.processed_files:
        st.warning("No processed audio files to export.")
        return
    
    # Create ZIP file in memory
    zip_buffer = io.BytesIO()
    
    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
        
        successful_files = [f for f in st.session_state.processed_files if f['status'] == 'success']
        
        for file_info in successful_files:
            output_path = Path(file_info['output_path'])
            
            if output_path.exists():
                # Determine archive path
                if create_species_folders:
                    archive_path = f"{file_info['species']}/{output_path.name}"
                else:
                    archive_path = output_path.name
                
                zip_file.write(output_path, archive_path)
    
    st.download_button(
        label="ðŸ“¥ Download Processed Audio Files",
        data=zip_buffer.getvalue(),
        file_name="batgentic_processed_audio.zip",
        mime="application/zip"
    )


def export_complete_package(format_type: str, include_metadata: bool, create_species_folders: bool, include_processed: bool):
    """Export complete analysis package."""
    
    zip_buffer = io.BytesIO()
    
    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
        
        # Add validation data
        if format_type == 'CSV':
            csv_data = st.session_state.validation_data.to_csv(index=False)
            zip_file.writestr("validation_data.csv", csv_data)
        
        # Add processed audio files
        if include_processed and st.session_state.processed_files:
            successful_files = [f for f in st.session_state.processed_files if f['status'] == 'success']
            
            for file_info in successful_files:
                output_path = Path(file_info['output_path'])
                
                if output_path.exists():
                    if create_species_folders:
                        archive_path = f"processed_audio/{file_info['species']}/{output_path.name}"
                    else:
                        archive_path = f"processed_audio/{output_path.name}"
                    
                    zip_file.write(output_path, archive_path)
        
        # Add metadata
        if include_metadata:
            # Processing log
            if st.session_state.processed_files:
                processing_df = pd.DataFrame(st.session_state.processed_files)
                processing_csv = processing_df.to_csv(index=False)
                zip_file.writestr("processing_log.csv", processing_csv)
            
            # Species summary
            species_summary = st.session_state.parser.get_species_summary()
            species_df = pd.DataFrame(list(species_summary.items()), columns=['Species', 'Count'])
            species_csv = species_df.to_csv(index=False)
            zip_file.writestr("species_summary.csv", species_csv)
            
            # Confidence statistics
            try:
                conf_stats = st.session_state.parser.get_confidence_stats()
                conf_df = pd.DataFrame([conf_stats])
                conf_csv = conf_df.to_csv(index=False)
                zip_file.writestr("confidence_statistics.csv", conf_csv)
            except:
                # Skip if confidence stats can't be generated
                pass
    
    st.download_button(
        label="ðŸ“¥ Download Complete Package",
        data=zip_buffer.getvalue(),
        file_name="batgentic_complete_analysis.zip",
        mime="application/zip"
    )


if __name__ == "__main__":
    main()
